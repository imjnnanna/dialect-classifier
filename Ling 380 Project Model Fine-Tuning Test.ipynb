{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "448e73c0-8609-444f-a71d-fd2f5f6675b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danielwang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopw = stopwords.words('english')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0abba31a-4ebf-4624-a195-232fd7a4bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"cleaned_slayer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "690961aa-5779-4659-9101-360ba10df585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>section_id</th>\n",
       "      <th>content</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>##87151</td>\n",
       "      <td>43 ripsnorter unplayable watson is gone and h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>##97951</td>\n",
       "      <td>welcome to the world confederation for physic...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>##209450</td>\n",
       "      <td>just over a week ago australia were bowled ou...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>##239752</td>\n",
       "      <td>release title 345612toolong 2007 release date...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>##411252</td>\n",
       "      <td>lte both radio and core network evolution is ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>1645</td>\n",
       "      <td>##1151552</td>\n",
       "      <td>study could advantageously be carried on by s...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>1646</td>\n",
       "      <td>##1153651</td>\n",
       "      <td>the official bit the concept of organic expre...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>1647</td>\n",
       "      <td>##1154050</td>\n",
       "      <td>nietzsche hegel and schopenhauer hegel and th...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>1648</td>\n",
       "      <td>##1154350</td>\n",
       "      <td>the forex market the foreign exchange market ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>1649</td>\n",
       "      <td>##1157850</td>\n",
       "      <td>some expo tourists dialed the summer hotline ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1650 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 section_id  \\\n",
       "0              0    ##87151   \n",
       "1              1    ##97951   \n",
       "2              2   ##209450   \n",
       "3              3   ##239752   \n",
       "4              4   ##411252   \n",
       "...          ...        ...   \n",
       "1645        1645  ##1151552   \n",
       "1646        1646  ##1153651   \n",
       "1647        1647  ##1154050   \n",
       "1648        1648  ##1154350   \n",
       "1649        1649  ##1157850   \n",
       "\n",
       "                                                content  file_name  \n",
       "0      43 ripsnorter unplayable watson is gone and h...          5  \n",
       "1      welcome to the world confederation for physic...          5  \n",
       "2      just over a week ago australia were bowled ou...          5  \n",
       "3      release title 345612toolong 2007 release date...          5  \n",
       "4      lte both radio and core network evolution is ...          5  \n",
       "...                                                 ...        ...  \n",
       "1645   study could advantageously be carried on by s...         16  \n",
       "1646   the official bit the concept of organic expre...         16  \n",
       "1647   nietzsche hegel and schopenhauer hegel and th...         16  \n",
       "1648   the forex market the foreign exchange market ...         16  \n",
       "1649   some expo tourists dialed the summer hotline ...         16  \n",
       "\n",
       "[1650 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3224a628-d3ee-4aaf-9667-e4c9e84ab203",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_texts = csv['content'].to_list()\n",
    "\n",
    "data_labels = csv['file_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32b6115c-adcc-4e5e-b85f-68a84069bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data_texts, data_labels, test_size = 0.2, random_state = 0 )\n",
    "\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts, train_labels, test_size = 0.01, random_state = 0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec07ba8c-4c1c-4f7d-af7d-61b3699d4df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning:\n",
      "\n",
      "`evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='574' max='574' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [574/574 39:04, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.915425</td>\n",
       "      <td>0.269697</td>\n",
       "      <td>0.113353</td>\n",
       "      <td>0.151310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.629339</td>\n",
       "      <td>0.421212</td>\n",
       "      <td>0.301976</td>\n",
       "      <td>0.329891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.575003</td>\n",
       "      <td>0.421212</td>\n",
       "      <td>0.305032</td>\n",
       "      <td>0.330303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.658770</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.284557</td>\n",
       "      <td>0.328103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.550100</td>\n",
       "      <td>0.847353</td>\n",
       "      <td>0.415152</td>\n",
       "      <td>0.281724</td>\n",
       "      <td>0.319383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=574, training_loss=0.4972773960658482, metrics={'train_runtime': 2346.8163, 'train_samples_per_second': 3.895, 'train_steps_per_second': 0.245, 'total_flos': 1211081748817920.0, 'train_loss': 0.4972773960658482, 'epoch': 7.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = predictions.argmax(axis=-1)  # Get the index of the highest logit as the predicted class\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "# Model and tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize the data\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Custom Dataset class for PyTorch\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# Convert to PyTorch Datasets\n",
    "train_dataset = TextDataset(train_encodings, train_labels)\n",
    "val_dataset = TextDataset(val_encodings, val_labels)\n",
    "\n",
    "# Model definition\n",
    "trainer_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=5)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=7,              \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=64,   \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=1e-5,               \n",
    "    logging_dir='./logs',            \n",
    "    evaluation_strategy=\"steps\",     \n",
    "    eval_steps=100                   \n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=trainer_model,                 \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1779128-d822-463f-9682-e71720561b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.save_model(\"file:///Users/danielwang/Ling%20380/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55125f7c-00bc-4101-9ca3-ea303a68ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a27c571f-6cf5-4e5e-8bd5-322ef0dd38b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric with errors='coerce' (turns invalid values into NaN)\n",
    "test['country'] = pd.to_numeric(test['country'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values (those that couldn't be converted)\n",
    "test = test.dropna(subset=['country'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "486440db-dd96-4e48-865b-72406c1ff2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>176501</td>\n",
       "      <td>Either you 're flat or I am . I beg your pardo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5992934</td>\n",
       "      <td>Good morning , kitty ! Come in here , baby ! I...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4613561</td>\n",
       "      <td>There 's a place called Penguin island In the ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3639561</td>\n",
       "      <td>- Thank you . That will be all , Moses . - Yes...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4613564</td>\n",
       "      <td>Hands up ! Your money or your life . Gim me th...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>676</td>\n",
       "      <td>4930051</td>\n",
       "      <td>Come inside . Come on in , boys . - The crowd ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>677</td>\n",
       "      <td>4535604</td>\n",
       "      <td>NARRATOR : In May of 2012 , Marshall and Lily ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>678</td>\n",
       "      <td>5809034</td>\n",
       "      <td>Previously on \" Missing \" ... Something 's hap...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>679</td>\n",
       "      <td>4833491</td>\n",
       "      <td>HANNAH : Fuck , I 'm crushed . MARNIE : No , y...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>680</td>\n",
       "      <td>5175894</td>\n",
       "      <td>- Previously on Haven ... It 's been three ses...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   fileID                                               text  \\\n",
       "0             0   176501  Either you 're flat or I am . I beg your pardo...   \n",
       "1             1  5992934  Good morning , kitty ! Come in here , baby ! I...   \n",
       "2             2  4613561  There 's a place called Penguin island In the ...   \n",
       "3             3  3639561  - Thank you . That will be all , Moses . - Yes...   \n",
       "4             4  4613564  Hands up ! Your money or your life . Gim me th...   \n",
       "..          ...      ...                                                ...   \n",
       "676         676  4930051  Come inside . Come on in , boys . - The crowd ...   \n",
       "677         677  4535604  NARRATOR : In May of 2012 , Marshall and Lily ...   \n",
       "678         678  5809034  Previously on \" Missing \" ... Something 's hap...   \n",
       "679         679  4833491  HANNAH : Fuck , I 'm crushed . MARNIE : No , y...   \n",
       "680         680  5175894  - Previously on Haven ... It 's been three ses...   \n",
       "\n",
       "     country  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        1.0  \n",
       "4        1.0  \n",
       "..       ...  \n",
       "676      1.0  \n",
       "677      1.0  \n",
       "678      1.0  \n",
       "679      1.0  \n",
       "680      1.0  \n",
       "\n",
       "[680 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a25461ab-e082-4124-a003-2c641d5990d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test['text'].to_list()\n",
    "\n",
    "test_labels = test['country'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "221e3280-24fb-46b7-92eb-14e99c2c8f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Load the tokenizer used during training\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize the test data\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "652c97c3-0971-4954-acc9-d851d7e7da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewTestDataset(Dataset):\n",
    "    def __init__(self, encodings, labels = None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# Instantiate dataset\n",
    "test_dataset = TextDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad44a4e6-7fc8-42dc-be0f-948066d8da40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eda013a1-e831-4670-8044-a5429804273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7558823529411764\n",
      "Test F1: 0.7686626742281454\n",
      "Test Precision: 0.7833735596130005\n"
     ]
    }
   ],
   "source": [
    "metrics = test_results.metrics\n",
    "print(f\"Test Accuracy: {metrics['test_accuracy']}\")\n",
    "print(f\"Test F1: {metrics['test_f1']}\")\n",
    "print(f\"Test Precision: {metrics['test_precision']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f808e2-9233-460b-aff8-d944e2dd18f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8993900418281555\n",
      "Validation Accuracy: 0.4212121212121212\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Output validation loss and accuracy\n",
    "validation_loss = eval_results.get(\"eval_loss\", None)\n",
    "accuracy = eval_results.get(\"eval_accuracy\", None)\n",
    "\n",
    "print(f\"Validation Loss: {validation_loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8cd06a0-41ec-4bf3-8061-e892b81a4fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870894c3-3819-4631-ab76-26131e598d1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Inference\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Tokenize the test input\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m test_text \u001b[38;5;241m=\u001b[39m \u001b[43mtest_texts\u001b[49m\n\u001b[1;32m      5\u001b[0m test_encoding \u001b[38;5;241m=\u001b[39m tokenizer(test_text, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_texts' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#Inference\n",
    "# Tokenize the test input\n",
    "test_text = test_texts\n",
    "test_encoding = tokenizer(test_text, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "trainer_model.eval()\n",
    "\n",
    "# Move tensors and model to the same device (CPU or GPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "trainer_model.to(device)\n",
    "test_encoding = {key: val.to(device) for key, val in test_encoding.items()}\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    output = trainer_model(**test_encoding)\n",
    "\n",
    "# Get the predicted class index\n",
    "logits = output.logits  # Access logits from the output\n",
    "predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
