{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "448e73c0-8609-444f-a71d-fd2f5f6675b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danielwang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopw = stopwords.words('english')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abba31a-4ebf-4624-a195-232fd7a4bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"cleaned_slayer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "690961aa-5779-4659-9101-360ba10df585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>section_id</th>\n",
       "      <th>content</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>##87151</td>\n",
       "      <td>43 ripsnorter unplayable watson is gone and h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>##97951</td>\n",
       "      <td>welcome to the world confederation for physic...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>##209450</td>\n",
       "      <td>just over a week ago australia were bowled ou...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>##239752</td>\n",
       "      <td>release title 345612toolong 2007 release date...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>##411252</td>\n",
       "      <td>lte both radio and core network evolution is ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>1645</td>\n",
       "      <td>##1151552</td>\n",
       "      <td>study could advantageously be carried on by s...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>1646</td>\n",
       "      <td>##1153651</td>\n",
       "      <td>the official bit the concept of organic expre...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>1647</td>\n",
       "      <td>##1154050</td>\n",
       "      <td>nietzsche hegel and schopenhauer hegel and th...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>1648</td>\n",
       "      <td>##1154350</td>\n",
       "      <td>the forex market the foreign exchange market ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>1649</td>\n",
       "      <td>##1157850</td>\n",
       "      <td>some expo tourists dialed the summer hotline ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1650 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 section_id  \\\n",
       "0              0    ##87151   \n",
       "1              1    ##97951   \n",
       "2              2   ##209450   \n",
       "3              3   ##239752   \n",
       "4              4   ##411252   \n",
       "...          ...        ...   \n",
       "1645        1645  ##1151552   \n",
       "1646        1646  ##1153651   \n",
       "1647        1647  ##1154050   \n",
       "1648        1648  ##1154350   \n",
       "1649        1649  ##1157850   \n",
       "\n",
       "                                                content  file_name  \n",
       "0      43 ripsnorter unplayable watson is gone and h...          5  \n",
       "1      welcome to the world confederation for physic...          5  \n",
       "2      just over a week ago australia were bowled ou...          5  \n",
       "3      release title 345612toolong 2007 release date...          5  \n",
       "4      lte both radio and core network evolution is ...          5  \n",
       "...                                                 ...        ...  \n",
       "1645   study could advantageously be carried on by s...         16  \n",
       "1646   the official bit the concept of organic expre...         16  \n",
       "1647   nietzsche hegel and schopenhauer hegel and th...         16  \n",
       "1648   the forex market the foreign exchange market ...         16  \n",
       "1649   some expo tourists dialed the summer hotline ...         16  \n",
       "\n",
       "[1650 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3224a628-d3ee-4aaf-9667-e4c9e84ab203",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_texts = csv['content'].to_list()\n",
    "\n",
    "data_labels = csv['file_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b6115c-adcc-4e5e-b85f-68a84069bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data_texts, data_labels, test_size = 0.2, random_state = 0 )\n",
    "\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts, train_labels, test_size = 0.01, random_state = 0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec07ba8c-4c1c-4f7d-af7d-61b3699d4df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning:\n",
      "\n",
      "`evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='574' max='574' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [574/574 22:29, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.881262</td>\n",
       "      <td>0.309091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.663727</td>\n",
       "      <td>0.430303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.623959</td>\n",
       "      <td>0.430303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.659847</td>\n",
       "      <td>0.427273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.550700</td>\n",
       "      <td>0.779766</td>\n",
       "      <td>0.442424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=574, training_loss=0.49774121573577773, metrics={'train_runtime': 1351.6125, 'train_samples_per_second': 6.764, 'train_steps_per_second': 0.425, 'total_flos': 1211081748817920.0, 'train_loss': 0.49774121573577773, 'epoch': 7.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = predictions.argmax(axis=-1)  # Get the index of the highest logit as the predicted class\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "# Model and tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize the data\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Custom Dataset class for PyTorch\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# Convert to PyTorch Datasets\n",
    "train_dataset = TextDataset(train_encodings, train_labels)\n",
    "val_dataset = TextDataset(val_encodings, val_labels)\n",
    "\n",
    "# Model definition\n",
    "trainer_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=5)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=7,              \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=64,   \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=1e-5,               \n",
    "    logging_dir='./logs',            \n",
    "    evaluation_strategy=\"steps\",     \n",
    "    eval_steps=100                   \n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=trainer_model,                 \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f808e2-9233-460b-aff8-d944e2dd18f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8993900418281555\n",
      "Validation Accuracy: 0.4212121212121212\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Output validation loss and accuracy\n",
    "validation_loss = eval_results.get(\"eval_loss\", None)\n",
    "accuracy = eval_results.get(\"eval_accuracy\", None)\n",
    "\n",
    "print(f\"Validation Loss: {validation_loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "870894c3-3819-4631-ab76-26131e598d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#Inference\n",
    "# Tokenize the test input\n",
    "test_text = test_texts\n",
    "test_encoding = tokenizer(test_text, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "trainer_model.eval()\n",
    "\n",
    "# Move tensors and model to the same device (CPU or GPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "trainer_model.to(device)\n",
    "test_encoding = {key: val.to(device) for key, val in test_encoding.items()}\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    output = trainer_model(**test_encoding)\n",
    "\n",
    "# Get the predicted class index\n",
    "logits = output.logits  # Access logits from the output\n",
    "predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
